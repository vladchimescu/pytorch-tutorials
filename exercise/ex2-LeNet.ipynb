{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9761b48e",
   "metadata": {},
   "source": [
    "# Convolutional Neural Nets in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82cfe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose, Normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38655833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64ddc5",
   "metadata": {},
   "source": [
    "Define a transform that first converts the original PIL image to a Tensor with float values in the range $[0,1]$ and then normalizes the values by subtracting the mean (`mu`) and dividing by standard deviation (`sd`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.5\n",
    "sd = 0.5\n",
    "\n",
    "# how to choose values of mu and sd in practice? is this important?\n",
    "transform = Compose(\n",
    "    [ToTensor(),\n",
    "     Normalize((mu, mu, mu), (sd, sd, sd))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09f3f1",
   "metadata": {},
   "source": [
    "Load CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', \n",
    "           'ship', 'truck')\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4f6bf",
   "metadata": {},
   "source": [
    "Create a `DataLoader` object that iterates over batches of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ea92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=8,\n",
    "                         shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=8,\n",
    "                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c074d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in trainloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, mean, sd):\n",
    "    img = img *sd + mean    # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "plt.figure(figsize=(16,2))\n",
    "# show images\n",
    "imshow(make_grid(images), mean=mu, sd=sd)\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels_map[labels[j]] for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70aa976",
   "metadata": {},
   "source": [
    "## Build LeNet\n",
    "\n",
    "Output size of convolutions:\n",
    "\n",
    "$$n_{out} = \\left\\lfloor \\frac{n_{in} + 2p - f}{s} \\right\\rfloor + 1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d08762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        cn = self.convolutions(x)\n",
    "        logits = self.fc_layers(cn)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb72c09",
   "metadata": {},
   "source": [
    "Instantiate a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a03d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.convolutions.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2348c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Layer 0, weight dimensions:\", model.convolutions[0].weight.shape)\n",
    "print(\"Layer 0, bias dimensions:\", model.convolutions[0].bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd83678",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Layer 3, weight dimensions: \", model.convolutions[3].weight.shape)\n",
    "print(\"Layer 3, bias dimensions: \", model.convolutions[3].bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a901f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        pred = model(X)\n",
    "        # compute loss\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        # reset gradients (otherwie they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        # run backpropagation\n",
    "        loss.backward()\n",
    "        # update the parameters of the model\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a521eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    # don't track the gradients\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # forward pass\n",
    "            pred = model(X)\n",
    "            # aggregate loss\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    # average loss\n",
    "    test_loss /= num_batches\n",
    "    # accuracy\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a20b1",
   "metadata": {},
   "source": [
    "Questions:\n",
    "+ Weight initialization? Not important in PyTorch\n",
    "+ Do we need to seed the results? Just globally with `torch.manual_seed()`? I can ask around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ab098",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(trainloader, model, loss_fn, optimizer)\n",
    "    test(testloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9526e6",
   "metadata": {},
   "source": [
    "We can use TensorBoard to visualize our model training and view individual train or test instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623574ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690668aa",
   "metadata": {},
   "source": [
    "For instance, we can show images in TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb860911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a batch of 4 images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "img_grid = make_grid(images)\n",
    "imshow(img_grid, mean=mu, sd=sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360ace0",
   "metadata": {},
   "source": [
    "Below, we use the `add_image()` call on `SummaryWriter` to log the image for consumption by TensorBoard, and we also call `flush()` to make sure it’s written to disk right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42304a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default log_dir argument is \"runs\" - but it's good to be specific\n",
    "# torch.utils.tensorboard.SummaryWriter is imported above\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "\n",
    "# Write image data to TensorBoard log dir\n",
    "writer.add_image('Four Fashion-MNIST Images', img_grid)\n",
    "writer.flush()\n",
    "\n",
    "# To view, start TensorBoard on the command line with:\n",
    "#   tensorboard --logdir=runs\n",
    "# ...and open a browser tab to http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f17618",
   "metadata": {},
   "source": [
    "Now let’s train a single epoch, and evaluate the training vs. validation set losses every 1000 batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfe2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34dcd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(testloader))\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # basic training loop\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # Every 1000 mini-batches...\n",
    "            print('Batch {}'.format(i + 1))\n",
    "            # Check against the validation set\n",
    "            running_vloss = 0.0\n",
    "\n",
    "            model.train(False) # Don't need to track gradents for validation\n",
    "            for j, vdata in enumerate(testloader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            model.train(True) # Turn gradients back on for training\n",
    "\n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(testloader)\n",
    "\n",
    "            # Log the running loss averaged per batch\n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80865c",
   "metadata": {},
   "source": [
    "TensorBoard can also be used to examine the data flow within your model. To do this, call the `add_graph()` method with a model and sample input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e167928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, grab a single mini-batch of images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# add_graph() will trace the sample input through your model,\n",
    "# and render it as a graph.\n",
    "writer.add_graph(model, images)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a5bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
